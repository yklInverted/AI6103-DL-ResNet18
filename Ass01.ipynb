{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "     #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20172547130>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(trainset[68][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining resnet models\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # This is the \"stem\"\n",
    "        # For CIFAR (32x32 images), it does not perform downsampling\n",
    "        # It should downsample for ImageNet\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # four stages with three downsampling\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test_resnet18():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())\n",
    "\n",
    "net = ResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\study\\NTU_LEARN\\AI6103 DEEP LEARNING\\assignment01\\Ass01.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/NTU_LEARN/AI6103%20DEEP%20LEARNING/assignment01/Ass01.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/NTU_LEARN/AI6103%20DEEP%20LEARNING/assignment01/Ass01.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/study/NTU_LEARN/AI6103%20DEEP%20LEARNING/assignment01/Ass01.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/NTU_LEARN/AI6103%20DEEP%20LEARNING/assignment01/Ass01.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/NTU_LEARN/AI6103%20DEEP%20LEARNING/assignment01/Ass01.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# print statistics\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32md:\\miniconda\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cuda = torch.device('cuda')\n",
    "net.to(cuda)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(cuda), labels.to(cuda)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "690c9ea092c8a6fc9517542155c4d05fadb9e10c4733225e6f103cd30826cc12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
